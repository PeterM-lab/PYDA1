{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь решаем задачу регрессии - предскажем цены на недвижимость. Использовать датасет www.kaggle.com...iques/data (train.csv)\n",
    "Данных немного, поэтому необходимо использовать 10-fold кросс-валидацию для оценки качества моделей\n",
    "Построить случайный лес, вывести важность признаков\n",
    "Обучить стекинг как минимум 3х моделей, использовать хотя бы 1 линейную модель и 1 нелинейную\n",
    "Для валидации модели 2-го уровня использовать отдельный hold-out датасет, как на занятии\n",
    "Показать, что использование ансамблей моделей действительно улучшает качество (стекинг vs другие модели сравнивать на hold-out)\n",
    "В качестве решения: Jupyter notebook с кодом, комментариями и графиками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#применим OneHotEncoder к категориальным переменным\n",
    "\n",
    "data1 = data.select_dtypes(exclude = np.object)\n",
    "data2 = pd.get_dummies(data.select_dtypes(include = np.object))\n",
    "data = pd.concat([data1, data2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    #заполняем пропуски либо наиболее повторяющимся значением для категориальных переменных, либо медианой\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == np.object:\n",
    "            df[col].fillna(df[col].mode().iloc[0], inplace = True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[data1.columns] = scaler.fit_transform(df[data1.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отдельно определим важность числовых и категориальных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_leaf=20, max_features=0.8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[data1.columns].drop('SalePrice', axis = 1)\n",
    "y = df['SalePrice']\n",
    "X.drop(['Id'], axis = 1, inplace = True)\n",
    "\n",
    "regressor.fit(X, y)\n",
    "\n",
    "nd_ar = regressor.feature_importances_\n",
    "forest_importances1 = pd.Series(nd_ar, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[data2.columns]\n",
    "y = df['SalePrice']\n",
    "\n",
    "regressor.fit(X, y)\n",
    "\n",
    "nd_ar = regressor.feature_importances_\n",
    "forest_importances2 = pd.Series(nd_ar, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_importances = forest_importances1.append(forest_importances2)\n",
    "forest_importances.sort_values(ascending = False, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances1.sort_values(ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовим обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('SalePrice', axis = 1)\n",
    "y = df['SalePrice']\n",
    "X.drop(['Id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(data1.columns)\n",
    "for item in ['Id','SalePrice']:\n",
    "    col.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-155-0d02be966169>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = scaler.transform(X_train[col])\n",
      "C:\\Users\\martynov\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-155-0d02be966169>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = scaler.transform(X_test[col])\n",
      "C:\\Users\\martynov\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(X_train[col])\n",
    "X_train[col] = scaler.transform(X_train[col])\n",
    "X_test[col] = scaler.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для линейной регрессии будем использовать первые 20 параметров по важности (числовых и категориальных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[forest_importances[:20].index]\n",
    "X_test1 = X_test[forest_importances[:20].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для нелинейной регрессии будем использовать первые 10 числовых параметров по важности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train[forest_importances1[:10].index]\n",
    "X_test2 = X_test[forest_importances1[:10].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf_lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly1 = PolynomialFeatures(interaction_only=True)\n",
    "poly2 = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посчитаем ошибку для каждой из трех моделей по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1675735394.2180805"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = clf_lr.fit(X_train1, y_train)\n",
    "y_pred = reg.predict(X_test1)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3057969192.511751"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = clf_lr.fit(poly1.fit_transform(X_train2), y_train)\n",
    "y_pred = reg.predict(poly1.fit_transform(X_test2))\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3511089414.7138944"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = clf_lr.fit(poly2.fit_transform(X_train2), y_train)\n",
    "y_pred = reg.predict(poly2.fit_transform(X_test2))\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_cv = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_features(clf, X_train, y_train, X_test, stack_cv):\n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(y_test, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(stack_cv.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind])\n",
    "        meta_train[test_ind] = clf.predict(X_train.iloc[test_ind])\n",
    "        meta_test += clf.predict(X_test)\n",
    "    \n",
    "    return meta_train, meta_test / stack_cv.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовим ансамбль моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "poly1\n",
      "poly2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martynov\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\martynov\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\martynov\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "meta_train = []\n",
    "meta_test = []\n",
    "col_names = []\n",
    "\n",
    "\n",
    "print('LinearRegression')\n",
    "meta_tr, meta_te = get_meta_features(clf_lr, X_train1, y_train, X_test1, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('lr_pred')\n",
    "\n",
    "print('poly1')\n",
    "X_train2_1 = pd.DataFrame(poly1.fit_transform(X_train2))\n",
    "X_test2_1 = pd.DataFrame(poly1.fit_transform(X_test2))\n",
    "meta_tr, meta_te = get_meta_features(clf_lr, X_train2_1, y_train, X_test2_1, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('poly1')\n",
    "\n",
    "print('poly2')\n",
    "X_train2_2 = pd.DataFrame(poly2.fit_transform(X_train2))\n",
    "X_test2_2 = pd.DataFrame(poly2.fit_transform(X_test2))\n",
    "meta_tr, meta_te = get_meta_features(clf_lr, X_train2_2, y_train, X_test2_2, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('poly2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_train = pd.DataFrame(np.stack(meta_train, axis=1), columns=col_names)\n",
    "X_meta_test = pd.DataFrame(np.stack(meta_test, axis=1), columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.fit(X_meta_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ошибка у стэкинга немного ниже, но всё равно большая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077780508.9741495"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_lr.predict(X_meta_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
